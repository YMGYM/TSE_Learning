{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Beijing_air_plollution_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1id0lidBw3ytHXqoXT-YdhGQF1i9OmpVG",
      "authorship_tag": "ABX9TyP4npX+5uYFoT4wvDfOQMqO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YMGYM/TSE_Learning/blob/master/Beijing_air_plollution_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMv9zH97I3bI",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "이 파일은 황철현, 신강욱의\n",
        "`미세먼지 예측 성능 개선을 위한 CNN-LSTM 결합 방법`\n",
        "논문의 구현 연습 파일입니다.\n",
        "\n",
        "데이터셋은 [Beijing PM2.5 데이터셋](https://www.kaggle.com/djhavera/beijing-pm25-data-data-set)\n",
        "을 사용했습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9yCDz1HI7Uo",
        "colab_type": "text"
      },
      "source": [
        "# Import All\n",
        "필요한 라이브러리들을 임포트합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm_0IVquJCbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as K\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_5bQtjaJJhO",
        "colab_type": "text"
      },
      "source": [
        "# Load Data\n",
        "구글 드라이브를 마운트하고, 구글 드라이브에 있는 데이터를 임포트합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhHDbpAyJSeG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f8d8ca4b-6316-461f-b672-038d7477592c"
      },
      "source": [
        "! unzip /content/drive/My\\ Drive/Datasets/beijing_air.zip -d data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/Datasets/beijing_air.zip\n",
            "  inflating: data/PRSA_data_2010.1.1-2014.12.31.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N74bTHyWJVrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data():\n",
        "  all_data = pd.read_csv('/content/data/PRSA_data_2010.1.1-2014.12.31.csv') # 전체 데이터\n",
        "  dropped_data = all_data.drop(['No', 'year', 'month', 'day', 'hour'],axis=1) # 필요 없는 데이터는 버림\n",
        "  pm25 = dropped_data.pop('pm2.5') # 미세먼지 데이터 확인\n",
        "  pm25 = pm25.fillna(method='pad')\n",
        "  \n",
        "  return pm25, dropped_data"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1KXPy5tJXhA",
        "colab_type": "text"
      },
      "source": [
        "# Define Scalers\n",
        "데이터를 정규화할 스케일러를 구현합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w84cArG1Jcpd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Scaler():\n",
        "  def __init__(self):\n",
        "    self.scaler = MinMaxScaler()\n",
        "    self.last_scaled_data = None\n",
        "\n",
        "  def data_normalize(self, data = None):\n",
        "    if isinstance(data, type(np.array([]))) == False:\n",
        "      reshaped = data.to_numpy().reshape(-1,1) # x 가 pandas 데이터인 경우 numpy로 변환 후 reshape 한다.\n",
        "    else:\n",
        "      reshaped = data.reshape(-1,1)\n",
        "\n",
        "    self.last_scaled_data = self.scaler.fit_transform(reshaped)\n",
        "\n",
        "    return self.last_scaled_data\n",
        "\n",
        "  def invert_scale(self, data):\n",
        "    # 정규화된 데이터를 원상태로 돌립니다.\n",
        "    return self.scaler.inverse_transform(data)\n",
        "\n",
        "  def slice_data(self, data, rate=0.1): # 데이터를 정해진 비율로 나눕니다.\n",
        "    arrlen = int(len(data) * rate)\n",
        "    train, val, test = data[:-1 * (arrlen * 2)], data[-1 * (arrlen * 2) : -1 * (arrlen)], data[-1 * (arrlen):]\n",
        "    return train, val, test"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VBXx10tKUUd",
        "colab_type": "text"
      },
      "source": [
        "## Pm2.5 Data Scaler\n",
        "미세먼지 데이터를 위한 Scaler 구현입니다. 기능은 동일합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvsfTffHKm3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PmScaler(Scaler):\n",
        "  def __init__(self):\n",
        "    super().__init__()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jBSB8NkM95v",
        "colab_type": "text"
      },
      "source": [
        "## Proxy Data Scaler\n",
        "주위 환경 정보용 Scaler 구현입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caONpXmSNG13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ProxyScaler(Scaler):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def change_cbwd_data(self, table): # 문자열로 된 풍향 정보를 숫자로 변환합니다.\n",
        "    mapping = {}\n",
        "    cols = table[\"cbwd\"].value_counts().index\n",
        "    for i, col in enumerate(cols):\n",
        "      mapping[col] = i\n",
        "    table = table.replace({'cbwd' : mapping})\n",
        "    print(\"cbwd data changed to number : {SE : 0, NW: 1, cv: 2, NE:3} \")\n",
        "\n",
        "    return table\n",
        "\n",
        "  def data_normalize(self, data):\n",
        "    norm_data = self.scaler.fit_transform(data)\n",
        "    return norm_data\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eup4SOeJOSC_",
        "colab_type": "text"
      },
      "source": [
        "# Make Custom Layer (Not Used)\n",
        "CNN 계층의 출력을 비율로 변환해주는 커스텀 계층입니다.\n",
        "\n",
        "현재는 사용하지 않습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iCR07elSv0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataCombine(K.layers.Layer):\n",
        "  def __init__(self, data, bins = None, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "\n",
        "    if bins == None:\n",
        "      self.bins = [-9.166667e-02, -1e-15,1e-15, 1.212121e-01]\n",
        "    else:\n",
        "      self.bins = bins\n",
        "\n",
        "    self.grad_data = pm25.pct_change().fillna(method=\"pad\")\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    # 예측량을 구함\n",
        "    rate = self._get_rate(data)\n",
        "    return rate * value.squeeze(axis=1)\n",
        "\n",
        "  def _get_rate(self, data):\n",
        "    # 변화율 별로 pm25의 예측량을 구해봄(임시)\n",
        "    index = data.argmax(axis=1)\n",
        "    rate = np.array([])\n",
        "    for i in range(len(index)):\n",
        "      if index[i] == 3:\n",
        "        rate = np.append(rate, 1)\n",
        "      else:\n",
        "        rate = np.append(rate, 1 + ((index[i]-3) * 0.25)) # 최대 50%의 변화율을 줘 봄\n",
        "    return rate\n",
        "\n",
        "  def _get_grad_pm25(self):\n",
        "    # pm25 의 변화율을 구하고 범주화함\n",
        "    grad_data = self.pm25.pct_change()\n",
        "    grad_data = grad_data.fillna(method=\"pad\")\n",
        "    bins = [-9.166667e-02, -1e-15,1e-15, 1.212121e-01]\n",
        "    # bins = [-10, -1e-15, 1e-15, 10]\n",
        "    grad_level = np.digitize(grad_data, bins=bins, right=False)\n",
        "    return grad_level\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6FoQlidVtbh",
        "colab_type": "text"
      },
      "source": [
        "# Custom Generator\n",
        "데이터 제공을 위한 커스텀 제너레이터 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOq6xMb-VxwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomGenerator(K.utils.Sequence):\n",
        "  def __init__(self, cnn_gen, lstm_gen):\n",
        "    self.cnn_gen = cnn_gen\n",
        "    self.lstm_gen = lstm_gen\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    cnn_x, cnn_y = self.cnn_gen[idx]\n",
        "    lstm_x, lstm_y = self.lstm_gen[idx]\n",
        "  \n",
        "    return [cnn_x, lstm_x], lstm_y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.cnn_gen.__len__() #위험!"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9zzf8N1YhIF",
        "colab_type": "text"
      },
      "source": [
        "# Make Model Trainer\n",
        "모델을 학습시켜주는 Trainer 클래스입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jufA_sTY6-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelTrainer():\n",
        "  def __init__(self, pm25, proxy):\n",
        "    # --------- 데이터 보관 --------\n",
        "    self.pm25 = pm25.fillna(1e-8,limit=1).fillna(method=\"pad\")\n",
        "    self.proxy = proxy\n",
        "    print(f\"pm25 length : {len(self.pm25)}\" )\n",
        "    print(f\"proxydata length : {len(self.proxy)}\" )\n",
        "\n",
        "    # --------- 스케일러 생성 --------\n",
        "    self.pmScaler = PmScaler()\n",
        "    self.proxyScaler = ProxyScaler()\n",
        "\n",
        "    # ---------- train 용 callbacks -----------\n",
        "    self.callbacks = [K.callbacks.TensorBoard(log_dir='model_logs')]\n",
        "\n",
        "\n",
        "  def data_preprocess(self, rate = 0.1): # 데이터 전처리\n",
        "    self.proxy = self.proxyScaler.change_cbwd_data(self.proxy)\n",
        "    # -------- 데이터 정규화 ---------\n",
        "    self.pm25 = self.pmScaler.data_normalize(self.pm25)\n",
        "    self.proxy = self.proxyScaler.data_normalize(self.proxy)\n",
        "    # -------- 데이터 분할 ----------\n",
        "    self.cnn_train, self.cnn_val, self.cnn_test = self.proxyScaler.slice_data(data=self.proxy, rate = rate)\n",
        "    self.lstm_train, self.lstm_val, self.lstm_test = self.pmScaler.slice_data(data=self.pm25, rate = rate)\n",
        "    print(f\"cnn_x_train : {len(self.cnn_train)}, cnn_x_val : {len(self.cnn_val)}, cnn_x_test length: {len(self.cnn_test)}\")\n",
        "    print(f\"lstm_x_train : {len(self.lstm_train)}, lstm_x_val : {len(self.lstm_val)}, lstm_x_test length: {len(self.lstm_test)}\")\n",
        "\n",
        "  def make_datagenerator(self, data_len = 15, batch_size = 1): # 데이터 제너레이터 생성\n",
        "\n",
        "    self.cnn_train_data_gen = K.preprocessing.sequence.TimeseriesGenerator(self.cnn_train, self.cnn_train, length=data_len, batch_size = batch_size, shuffle=True)\n",
        "    self.cnn_val_data_gen = K.preprocessing.sequence.TimeseriesGenerator(self.cnn_val, self.cnn_val, length=data_len, batch_size = batch_size, shuffle=True)\n",
        "    self.cnn_test_data_gen = K.preprocessing.sequence.TimeseriesGenerator(self.cnn_test, self.cnn_test, length=data_len, batch_size = batch_size, shuffle=False)\n",
        "    print(f\"cnn_train_data_gen length : {self.cnn_train_data_gen.__len__()} // data_len: {data_len}\" )\n",
        "    print(f\"cnn_val_data_gen length : {self.cnn_val_data_gen.__len__()} // data_len: {data_len}\" )\n",
        "    print(f\"cnn_test_data_gen length : {self.cnn_test_data_gen.__len__()} // data_len: {data_len}\" )\n",
        "\n",
        "    self.lstm_train_data_gen = K.preprocessing.sequence.TimeseriesGenerator(self.lstm_train, self.lstm_train, length=data_len, batch_size = batch_size, shuffle=True)\n",
        "    self.lstm_val_data_gen = K.preprocessing.sequence.TimeseriesGenerator(self.lstm_val, self.lstm_val, length=data_len, batch_size = batch_size, shuffle=True)\n",
        "    self.lstm_test_data_gen = K.preprocessing.sequence.TimeseriesGenerator(self.lstm_test, self.lstm_test, length=data_len, batch_size = batch_size, shuffle=False)\n",
        "    print(f\"lstm_train_data_gen length : {self.lstm_train_data_gen.__len__()} // data_len: {data_len}\" )\n",
        "    print(f\"lstm_val_data_gen length : {self.lstm_val_data_gen.__len__()} // data_len: {data_len}\" )\n",
        "    print(f\"lstm_test_data_gen length : {self.lstm_test_data_gen.__len__()} // data_len: {data_len}\" )\n",
        "\n",
        "    self.total_train_data_gen = CustomGenerator(self.cnn_train_data_gen, self.lstm_train_data_gen)\n",
        "    self.total_val_data_gen = CustomGenerator(self.cnn_val_data_gen, self.lstm_val_data_gen)\n",
        "    self.total_test_data_gen = CustomGenerator(self.cnn_test_data_gen, self.lstm_test_data_gen)\n",
        "    print(\"total data generator generated\")\n",
        "\n",
        "  def generate_model(self): # 모델을 생성함\n",
        "    cnn_x, cnn_y = self.cnn_train_data_gen[0]\n",
        "    lstm_x, lstm_y = self.lstm_train_data_gen[0]\n",
        "\n",
        "    cnn_input = K.layers.Input(shape=(cnn_x.shape[1], cnn_x.shape[2])) # (행, 열)\n",
        "    lstm_input = K.layers.Input(shape=(lstm_x.shape[1], lstm_x.shape[2])) # (시간 수, 1)\n",
        "\n",
        "    reshape1 = K.layers.Reshape(target_shape=(1, cnn_x.shape[1], cnn_x.shape[2]))(cnn_input) #(배치, 차원 = 1, 행, 열)\n",
        "    cnn1 = K.layers.Conv2DTranspose(32, (2,2), activation=\"relu\")(reshape1)\n",
        "    maxpool1 = K.layers.MaxPool2D(strides=2)(cnn1)\n",
        "    flatten = K.layers.Flatten()(maxpool1)\n",
        "    dropout1 = K.layers.Dropout(0.1)(flatten)\n",
        "    dense1 = K.layers.Dense(100, activation=\"relu\")(dropout1)\n",
        "    dense2 = K.layers.Dense(1, activation=\"sigmoid\")(dense1)\n",
        "\n",
        "    reshape2 = K.layers.Reshape(target_shape=(-1, 1))(dense2) # (결과 값 수 , 1)\n",
        "    concat = K.layers.Concatenate(axis=1)([lstm_input, reshape2])\n",
        "\n",
        "    lstm1 = K.layers.LSTM(216)(concat)\n",
        "    dropout2 = K.layers.Dropout(0.3)(lstm1)\n",
        "    dense3 = K.layers.Dense(128, activation='relu')(dropout2)\n",
        "    dropout3 = K.layers.Dropout(0.3)(dense3)\n",
        "    dense4 = K.layers.Dense(1, activation=\"sigmoid\")(dropout3)\n",
        "\n",
        "    self.model = K.models.Model(inputs=[cnn_input,lstm_input] , outputs=dense4)\n",
        "    self.model.summary()\n",
        "\n",
        "    self.model.compile(loss=\"MSE\", optimizer = \"adam\")\n",
        "    return self.model\n",
        "\n",
        "  def fit(self, epochs=1): # 모델 학습\n",
        "    self.model.fit(x = self.total_train_data_gen, epochs=epochs, shuffle=True, validation_data=(self.total_val_data_gen), callbacks=self.callbacks)\n",
        "\n",
        "  def evaluate(self): #테스트 데이터로 모델 평가\n",
        "    self.model.evaluate(x = self.total_test_data_gen,)\n",
        "\n",
        "  def predict(self, data = None): # 데이터 입력받아 예측함 => 클래스 밖에서도 model.fit 으로 호출 가능\n",
        "    if data is None:\n",
        "      data = self.total_test_data_gen\n",
        "\n",
        "    prediction = self.model.predict(data)\n",
        "    return self.pmScaler.invert_scale(prediction)\n",
        "\n",
        "  def plot(self): # 그래프로 그립니다.\n",
        "    predict = self.predict()\n",
        "    plt.plot(self.pmScaler.invert_scale(self.lstm_test), label=\"Actual\")\n",
        "    plt.plot(predict, label=\"Predicted\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Compare Predict With Actual Data\")\n",
        "    plt.show()\n",
        "\n",
        "  def load_model(self, path): # 저장된 모델을 불러옵니다.\n",
        "    self.model = K.models.load_model(path)\n",
        "    print(f\"model loaded from {path}\")\n",
        "    return self.model\n",
        "\n",
        "  def save_model(self, path): # 모델을 \n",
        "    self.model.save(path)\n",
        "    print(f\"model saved at {path}\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6Mzm6o1K_q6",
        "colab_type": "text"
      },
      "source": [
        "# 실제 코드 실행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkocI0fPNNSO",
        "colab_type": "text"
      },
      "source": [
        "미세먼지 데이터와 대기 환경 데이터를 한 번에 불러 옵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohvjgwspajGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pm25, proxy = get_data()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbtXn3thNR5I",
        "colab_type": "text"
      },
      "source": [
        "ModelTrainer 클래스를 생성합니다.\n",
        "\n",
        "위에서 작업한 코드를 모두 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIkoSocyalY8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "07ff63c1-80ac-4680-8e81-fd19956b79a1"
      },
      "source": [
        "trainer = ModelTrainer(pm25, proxy)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pm25 length : 43824\n",
            "proxydata length : 43824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSNaIK7RNZh9",
        "colab_type": "text"
      },
      "source": [
        "기존에 가지고 있던 데이터를 가지고 결측치 제거, 정규화, 분할을 수행합니다.\n",
        "\n",
        "rate는 데이터를 학습, 검증, 테스트 데이터로 나누는 비율을 의미합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HANN9rgTao0T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ff6570dd-a7b1-4546-c252-24cfc5b5dd62"
      },
      "source": [
        "trainer.data_preprocess(rate=0.1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cbwd data changed to number : {SE : 0, NW: 1, cv: 2, NE:3} \n",
            "cnn_x_train : 35060, cnn_x_val : 4382, cnn_x_test length: 4382\n",
            "lstm_x_train : 35060, lstm_x_val : 4382, lstm_x_test length: 4382\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MoGwUE4Nsbe",
        "colab_type": "text"
      },
      "source": [
        "만들어 둔 데이터를 가지고 Datagenerator 를 생성합니다.\n",
        "\n",
        "data_len은 얼마만큼의 시간 길이를 쓸 것인가를 의미합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g68JCQXfatfb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "fd850ea2-ef57-4aaf-dd8f-3134d12dd3b4"
      },
      "source": [
        "trainer.make_datagenerator(data_len = 15, batch_size = 128)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cnn_train_data_gen length : 274 // data_len: 15\n",
            "cnn_val_data_gen length : 35 // data_len: 15\n",
            "cnn_test_data_gen length : 35 // data_len: 15\n",
            "lstm_train_data_gen length : 274 // data_len: 15\n",
            "lstm_val_data_gen length : 35 // data_len: 15\n",
            "lstm_test_data_gen length : 35 // data_len: 15\n",
            "total data generator generated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c8ehMTGOABT",
        "colab_type": "text"
      },
      "source": [
        "모델을 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrDBS24a6XpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = trainer.generate_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRaWg7ZiOCEF",
        "colab_type": "text"
      },
      "source": [
        "모델을 학습시키거나, 이미 저장된 가중치를 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_ACBtptBrzA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "067075d1-5c02-4247-c609-3d3e9f19d01f"
      },
      "source": [
        "# trainer.fit(epochs=60)\n",
        "trainer.load_model('/content/drive/My Drive/trained_model/AirPollution3')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model loaded from /content/drive/My Drive/trained_model/AirPollution3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.functional.Functional at 0x7f11745dd908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvtzIbPJOJnK",
        "colab_type": "text"
      },
      "source": [
        "모델이 올바르게 학습되었는가를 확인하는 코드입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9HqoARKB213",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.evaluate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhXGE6ZyONE4",
        "colab_type": "text"
      },
      "source": [
        "실제 모델이 미세먼지 값을 예측합니다.\n",
        "\n",
        "인자로 아무 것도 주어지지 않으면 ModelTrainer 클래스의 테스트 데이터로 작업을 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1i-r2AFIUC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = trainer.predict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp0vLp05OdPa",
        "colab_type": "text"
      },
      "source": [
        "ModelTrainer 클래스의 테스트 데이터를 가지고 실제 데이터와 비교해 그래프를 그립니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS86nSaAIbBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtRc7gFPOn5q",
        "colab_type": "text"
      },
      "source": [
        "# Tensorboard\n",
        "텐서보드는 모델의 학습 상황을 실시간으로 나타내는 익스텐션입니다.\n",
        "\n",
        "오차율 변동 사항을 에포크 별로 확인이 가능합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIOnfa0LMhdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGs7H6tmNEEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir {'model_logs'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EUTjUjOO2S7",
        "colab_type": "text"
      },
      "source": [
        "# 시연\n",
        "위에서 가져 온 베이징 데이터로 작업을 수행합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKIVe_rtPK9N",
        "colab_type": "text"
      },
      "source": [
        "현재 43824개의 데이터가 존재합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwi6LO3RO8a1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55d5963f-5ce9-49e0-90da-0310dd28fbf8"
      },
      "source": [
        "pm25, proxy = get_data()\n",
        "print(f\"proxy data len : {len(proxy)}, pm25 data len {len(pm25)}\")"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "proxy data len : 43824, pm25 data len 43824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FayQAKA1Qh6r",
        "colab_type": "text"
      },
      "source": [
        "Pandas 데이터 자료형을 Numpy 배열로 변경하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJO_zbgbQagX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np_pm25 = pm25.to_numpy()"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "691kSkwUPIs5",
        "colab_type": "text"
      },
      "source": [
        "이중에서 랜덤으로 하나를 골라 계측값을 확인하겠습니다.\n",
        "\n",
        "4382개의 Test데이터가 있었으므로 이 중에서 하나를 측정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-xbRQRmPVNQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ac6b9b8-f5fd-4875-9844-285f579e5531"
      },
      "source": [
        "import random\n",
        "idx = random.randint(4382, len(np_pm25))\n",
        "print(f\"idx : {idx}, proxy[-idx]: {np_proxy[-idx]}, pm25[-idx]: {np_pm25[-idx]}\")"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "idx : 23768, proxy[-idx]: [6 23.0 1007.0 'SE' 10.73 0 0], pm25[-idx]: 24.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-PIz8eDQHTX",
        "colab_type": "text"
      },
      "source": [
        "데이터를 전처리합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz8gGcoLQ5zG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a8e868b-90de-427f-99eb-d8a9d538c58f"
      },
      "source": [
        "pmScaler = PmScaler()\n",
        "proxyScaler = ProxyScaler()\n",
        "\n",
        "norm_pm25 = pmScaler.data_normalize(data = np_pm25)\n",
        "changed_proxy = proxyScaler.change_cbwd_data(proxy)\n",
        "norm_proxy = proxyScaler.data_normalize(data = changed_proxy)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cbwd data changed to number : {SE : 0, NW: 1, cv: 2, NE:3} \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmCOguLGRnYa",
        "colab_type": "text"
      },
      "source": [
        "모델 트레이너 클래스를 생성하고, 모델을 불러 옵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLUHTNw0UmLE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6fb208a9-6b8d-479c-bfa8-f6f06ce9c98e"
      },
      "source": [
        "trainer = ModelTrainer(pm25, proxy) # 인자는 기존 학습의 잔재입니다.\n",
        "trainer.load_model('/content/drive/My Drive/trained_model/AirPollution3')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pm25 length : 43824\n",
            "proxydata length : 43824\n",
            "model loaded from /content/drive/My Drive/trained_model/AirPollution3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.functional.Functional at 0x7f11cd085400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7DEhMxzVGjZ",
        "colab_type": "text"
      },
      "source": [
        "시간 축 데이터가 15단위이므로, idx의 15시간 전 데이터를 넣겠습니다.\n",
        "\n",
        "배치 사이즈가 1이므로 첫 번째 차원을 1로 변경합니다.(reshape)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XoKowrDVdl8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_proxy = norm_proxy[-idx - 16 : -idx-1].reshape(1,15,-1)\n",
        "input_pm25 = norm_pm25[-idx - 16 : -idx-1].reshape(1,15,-1)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NNHCATPV-h9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "be36ec25-d6a5-4219-b425-89504dc3be31"
      },
      "source": [
        "print(input_proxy.shape)\n",
        "print(input_pm25.shape)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 15, 7)\n",
            "(1, 15, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POwN3tVBW7ym",
        "colab_type": "text"
      },
      "source": [
        "모델을 사용해 예측합니다.\n",
        "\n",
        "두 개의 입력을 array 로 입력해 주어야 합니다. ([cnn_input, lstm_input])의 모양"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR6VBaW7VvRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = trainer.model.predict([input_proxy, input_pm25])"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SldCPZwIXO9A",
        "colab_type": "text"
      },
      "source": [
        "정규화 한 값을 원래 값으로 되돌립니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8JWBYzzV7At",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "invert_prediction = pmScaler.invert_scale(prediction)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR_0IaobXYOv",
        "colab_type": "text"
      },
      "source": [
        "값을 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1BHTSEJWZZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e81a66f-bb34-4771-d3d6-3e0156364cd0"
      },
      "source": [
        "print(f\"Prediction value : {invert_prediction[0][0]}, Actual value : {np_pm25[-idx]}\")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction value : 34.23979568481445, Actual value : 24.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtZDF9R7X2_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}