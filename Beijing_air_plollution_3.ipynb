{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Beijing_air_plollution_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1id0lidBw3ytHXqoXT-YdhGQF1i9OmpVG",
      "authorship_tag": "ABX9TyMG4TF0Q6ehEyr69jn+qR5M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YMGYM/TSE_Learning/blob/master/Beijing_air_plollution_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMv9zH97I3bI",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "이 파일은 황철현, 신강욱의\n",
        "`미세먼지 예측 성능 개선을 위한 CNN-LSTM 결합 방법`\n",
        "논문의 구현 연습 파일입니다.\n",
        "\n",
        "데이터셋은 [Beijing PM2.5 데이터셋](https://www.kaggle.com/djhavera/beijing-pm25-data-data-set)\n",
        "을 사용했습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9yCDz1HI7Uo",
        "colab_type": "text"
      },
      "source": [
        "# Import All\n",
        "필요한 라이브러리들을 임포트합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm_0IVquJCbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as K\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_5bQtjaJJhO",
        "colab_type": "text"
      },
      "source": [
        "# Load Data\n",
        "구글 드라이브를 마운트하고, 구글 드라이브에 있는 데이터를 임포트합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhHDbpAyJSeG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "40a85af5-9b80-4ef1-96f8-4a276f781a1a"
      },
      "source": [
        "! unzip /content/drive/My\\ Drive/Datasets/beijing_air.zip -d data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/Datasets/beijing_air.zip\n",
            "  inflating: data/PRSA_data_2010.1.1-2014.12.31.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N74bTHyWJVrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data():\n",
        "  all_data = pd.read_csv('/content/data/PRSA_data_2010.1.1-2014.12.31.csv') # 전체 데이터\n",
        "  dropped_data = all_data.drop(['No', 'year', 'month', 'day', 'hour'],axis=1) # 필요 없는 데이터는 버림\n",
        "  pm25 = dropped_data.pop('pm2.5') # 미세먼지 데이터 확인\n",
        "  pm25 = pm25.fillna(method='pad')\n",
        "  \n",
        "  return pm25, dropped_data"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1KXPy5tJXhA",
        "colab_type": "text"
      },
      "source": [
        "# Define Scalers\n",
        "데이터를 정규화할 스케일러를 구현합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w84cArG1Jcpd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Scaler():\n",
        "  def __init__(self):\n",
        "    self.scaler = MinMaxScaler()\n",
        "    self.last_scaled_data = None\n",
        "\n",
        "  def data_normalize(self, data = None):\n",
        "    if isinstance(data, type(np.array([]))) == False:\n",
        "      reshaped = data.to_numpy().reshape(-1,1) # x 가 pandas 데이터인 경우 numpy로 변환 후 reshape 한다.\n",
        "    else:\n",
        "      reshaped = data.reshape(-1,1)\n",
        "\n",
        "    self.last_scaled_data = self.scaler.fit_transform(reshaped)\n",
        "\n",
        "    return self.last_scaled_data\n",
        "\n",
        "  def invert_scale(self, data):\n",
        "    # 정규화된 데이터를 원상태로 돌립니다.\n",
        "    return self.scaler.inverse_transform(data)\n",
        "\n",
        "  def slice_data(self, data, rate=0.1): # 데이터를 정해진 비율로 나눕니다.\n",
        "    arrlen = int(len(data) * rate)\n",
        "    train, val, test = data[:-1 * (arrlen * 2)], data[-1 * (arrlen * 2) : -1 * (arrlen)], data[-1 * (arrlen):]\n",
        "    return train, val, test"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VBXx10tKUUd",
        "colab_type": "text"
      },
      "source": [
        "## Pm2.5 Data Scaler\n",
        "미세먼지 데이터를 위한 Scaler 구현입니다. 기능은 동일합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvsfTffHKm3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PmScaler(Scaler):\n",
        "  def __init__(self, pm25, data_len = 2):\n",
        "    super().__init__()"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jBSB8NkM95v",
        "colab_type": "text"
      },
      "source": [
        "## Proxy Data Scaler\n",
        "주위 환경 정보용 Scaler 구현입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caONpXmSNG13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ProxyScaler(Scaler):\n",
        "  def __init__(self, data):\n",
        "    super().__init__()\n",
        "    # self.table = data\n",
        "  \n",
        "  def change_cbwd_data(self, table): # 문자열로 된 풍향 정보를 숫자로 변환합니다.\n",
        "    mapping = {}\n",
        "    cols = table[\"cbwd\"].value_counts().index\n",
        "    for i, col in enumerate(cols):\n",
        "      mapping[col] = i\n",
        "    table = table.replace({'cbwd' : mapping})\n",
        "    print(\"cbwd data changed to number : {SE : 0, NW: 1, cv: 2, NE:3} \")\n",
        "\n",
        "    return table\n",
        "\n",
        "  def data_normalize(self, data):\n",
        "    norm_data = self.scaler.fit_transform(data)\n",
        "    return norm_data\n",
        "    "
      ],
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eup4SOeJOSC_",
        "colab_type": "text"
      },
      "source": [
        "# Make Custom Layer\n",
        "CNN 계층의 출력을 비율로 변환해주는 커스텀 계층입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iCR07elSv0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataCombine(K.layers.Layer):\n",
        "  def __init__(self, data, bins = None, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "\n",
        "    if bins == None:\n",
        "      self.bins = [-9.166667e-02, -1e-15,1e-15, 1.212121e-01]\n",
        "    else:\n",
        "      self.bins = bins\n",
        "\n",
        "    self.grad_data = pm25.pct_change().fillna(method=\"pad\")\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    # 예측량을 구함\n",
        "    rate = self._get_rate(data)\n",
        "    return rate * value.squeeze(axis=1)\n",
        "\n",
        "  def _get_rate(self, data):\n",
        "    # 변화율 별로 pm25의 예측량을 구해봄(임시)\n",
        "    index = data.argmax(axis=1)\n",
        "    rate = np.array([])\n",
        "    for i in range(len(index)):\n",
        "      if index[i] == 3:\n",
        "        rate = np.append(rate, 1)\n",
        "      else:\n",
        "        rate = np.append(rate, 1 + ((index[i]-3) * 0.25)) # 최대 50%의 변화율을 줘 봄\n",
        "    return rate\n",
        "\n",
        "  def _get_grad_pm25(self):\n",
        "    # pm25 의 변화율을 구하고 범주화함\n",
        "    grad_data = self.pm25.pct_change()\n",
        "    grad_data = grad_data.fillna(method=\"pad\")\n",
        "    bins = [-9.166667e-02, -1e-15,1e-15, 1.212121e-01]\n",
        "    # bins = [-10, -1e-15, 1e-15, 10]\n",
        "    grad_level = np.digitize(grad_data, bins=bins, right=False)\n",
        "    return grad_level\n"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6FoQlidVtbh",
        "colab_type": "text"
      },
      "source": [
        "# Custom Generator\n",
        "데이터 제공을 위한 커스텀 제너레이터 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOq6xMb-VxwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomGenerator(K.utils.Sequence):\n",
        "  def __init__(self, cnn_gen, lstm_gen):\n",
        "    self.cnn_gen = cnn_gen\n",
        "    self.lstm_gen = lstm_gen\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    cnn_x, cnn_y = self.cnn_gen[idx]\n",
        "    lstm_x, lstm_y = self.lstm_gen[idx]\n",
        "    \n",
        "    return [cnn_x, lstm_x], lstm_y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.cnn_gen.__len__() #위험!"
      ],
      "execution_count": 470,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9zzf8N1YhIF",
        "colab_type": "text"
      },
      "source": [
        "# Make Model Trainer\n",
        "모델을 학습시켜주는 Trainer 클래스입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jufA_sTY6-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelTrainer():\n",
        "  def __init__(self, pm25, proxy):\n",
        "    # --------- 데이터 보관 --------\n",
        "    self.pm25 = pm25.fillna(1e-8,limit=1).fillna(method=\"pad\")\n",
        "    self.proxy = proxy\n",
        "    print(f\"pm25 length : {len(self.pm25)}\" )\n",
        "    print(f\"proxydata length : {len(self.proxy)}\" )\n",
        "\n",
        "    # --------- 스케일러 생성 --------\n",
        "    self.pmScaler = PmScaler(self.pm25)\n",
        "    self.proxyScaler = ProxyScaler(self.proxy)\n",
        "\n",
        "    # ---------- train 용 callbacks -----------\n",
        "    self.callbacks = [K.callbacks.TensorBoard(log_dir='model_logs')]\n",
        "\n",
        "\n",
        "  def data_preprocess(self, rate = 0.1): # 데이터 전처리\n",
        "    self.proxy = self.proxyScaler.change_cbwd_data(self.proxy)\n",
        "    # -------- 데이터 정규화 ---------\n",
        "    self.pm25 = self.pmScaler.data_normalize(self.pm25)\n",
        "    self.proxy = self.proxyScaler.data_normalize(self.proxy)\n",
        "    # -------- 데이터 분할 ----------\n",
        "    self.cnn_train, self.cnn_val, self.cnn_test = self.proxyScaler.slice_data(data=self.proxy, rate = rate)\n",
        "    self.lstm_train, self.lstm_val, self.lstm_test = self.pmScaler.slice_data(data=self.pm25, rate = rate)\n",
        "    print(f\"cnn_x_train : {len(self.cnn_train)}, cnn_x_val : {len(self.cnn_val)}, cnn_x_test length: {len(self.cnn_test)}\")\n",
        "    print(f\"lstm_x_train : {len(self.lstm_train)}, lstm_x_val : {len(self.lstm_val)}, lstm_x_test length: {len(self.lstm_test)}\")\n",
        "\n",
        "  def make_datagenerator(self, lstm_data_len=15, cnn_data_len=2, batch_size = 1): # 데이터 제너레이터 생성\n",
        "\n",
        "    self.cnn_train_data_gen = K.preprocessing.sequence.TimeseriesGenerator(self.cnn_train, self.cnn_train, length=cnn_data_len, batch_size = batch_size, shuffle=True)\n",
        "    self.cnn_val_data_gen = K.preprocessing.sequence.TimeseriesGenerator(self.cnn_val, self.cnn_val, length=cnn_data_len, batch_size = batch_size, shuffle=True)\n",
        "    self.cnn_test_data_gen = K.preprocessing.sequence.TimeseriesGenerator(self.cnn_test, self.cnn_test, length=cnn_data_len, batch_size = 1, shuffle=False)\n",
        "    print(f\"cnn_train_data_gen length : {self.cnn_train_data_gen.__len__()} // data_len: {cnn_data_len}\" )\n",
        "    print(f\"cnn_val_data_gen length : {self.cnn_val_data_gen.__len__()} // data_len: {cnn_data_len}\" )\n",
        "    print(f\"cnn_test_data_gen length : {self.cnn_test_data_gen.__len__()} // data_len: {cnn_data_len}\" )\n",
        "\n",
        "    self.lstm_train_data_gen = K.preprocessing.sequence.TimeseriesGenerator(self.lstm_train, self.lstm_train, length=lstm_data_len, batch_size = batch_size, shuffle=True)\n",
        "    self.lstm_val_data_gen = K.preprocessing.sequence.TimeseriesGenerator(self.lstm_val, self.lstm_val, length=lstm_data_len, batch_size = batch_size, shuffle=True)\n",
        "    self.lstm_test_data_gen = K.preprocessing.sequence.TimeseriesGenerator(self.lstm_test, self.lstm_test, length=lstm_data_len, batch_size = 1, shuffle=False)\n",
        "    print(f\"lstm_train_data_gen length : {self.lstm_train_data_gen.__len__()} // data_len: {lstm_data_len}\" )\n",
        "    print(f\"lstm_val_data_gen length : {self.lstm_val_data_gen.__len__()} // data_len: {lstm_data_len}\" )\n",
        "    print(f\"lstm_test_data_gen length : {self.lstm_test_data_gen.__len__()} // data_len: {lstm_data_len}\" )\n",
        "\n",
        "    self.total_train_data_gen = CustomGenerator(self.cnn_train_data_gen, self.lstm_train_data_gen)\n",
        "    self.total_val_data_gen = CustomGenerator(self.cnn_val_data_gen, self.lstm_val_data_gen)\n",
        "    self.total_test_data_gen = CustomGenerator(self.cnn_test_data_gen, self.lstm_test_data_gen)\n",
        "    print(\"total data generator generated\")\n",
        "\n",
        "  def _make_generator(self, cnn_gen, lstm_gen): #모델 학습을 위한 더미 제너레이터 생성\n",
        "    return CustomGenerator(cnn_gen, lstm_gen)\n",
        "    \n",
        "  def generate_model(self): # 모델을 생성함\n",
        "    cnn_x, cnn_y = self.cnn_train_data_gen[0]\n",
        "    lstm_x, lstm_y = self.lstm_train_data_gen[0]\n",
        "\n",
        "    cnn_input = K.layers.Input(shape=(1, cnn_x.shape[1], cnn_x.shape[2])) # (차원 수, 행, 열)\n",
        "    lstm_input = K.layers.Input(shape=(lstm_x.shape[0], lstm_x.shape[1])) # (시간 수, 1)\n",
        "    cnn1 = K.layers.Conv2DTranspose(32, (2,2), activation=\"relu\")(cnn_input)\n",
        "    maxpool1 = K.layers.MaxPool2D(strides=2)(cnn1)\n",
        "    flatten = K.layers.Flatten()(maxpool1)\n",
        "    dropout1 = K.layers.Dropout(0.1)(flatten)\n",
        "    dense1 = K.layers.Dense(100, activation=\"relu\")(dropout1)\n",
        "    dense2 = K.layers.Dense(1, activation=\"sigmoid\")(dense1)\n",
        "\n",
        "    reshape = K.layers.Reshape(target_shape=(1,-1))(dense2)\n",
        "    concat = K.layers.Concatenate()([lstm_input, reshape])\n",
        "\n",
        "    lstm1 = K.layers.LSTM(216)(concat)\n",
        "    dropout2 = K.layers.Dropout(0.3)(lstm1)\n",
        "    dense3 = K.layers.Dense(128, activation='relu')(dropout2)\n",
        "    dropout3 = K.layers.Dropout(0.3)(dense3)\n",
        "    dense4 = K.layers.Dense(1, activation=\"sigmoid\")(dropout3)\n",
        "\n",
        "    self.model = K.models.Model(inputs=[cnn_input,lstm_input] , outputs=dense4)\n",
        "    self.model.summary()\n",
        "\n",
        "    self.model.compile(loss=\"RMSE\", optimizer = \"adam\")\n",
        "    return self.model\n",
        "\n",
        "  def fit(self, epochs=1): # 모델 학습\n",
        "    self.model.fit(x = self.total_train_data_gen, epochs=epochs, shuffle=True, callbacks=self.callbacks)\n"
      ],
      "execution_count": 471,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohvjgwspajGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pm25, proxy = get_data()"
      ],
      "execution_count": 472,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIkoSocyalY8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b0ca8c13-a7ae-4fa9-929f-df20c949afa6"
      },
      "source": [
        "trainer = ModelTrainer(pm25[:1000], proxy[:1000])"
      ],
      "execution_count": 473,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pm25 length : 1000\n",
            "proxydata length : 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HANN9rgTao0T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3fb33a1e-58fa-4342-ba24-c91d54a11c36"
      },
      "source": [
        "trainer.data_preprocess(rate=0.1)"
      ],
      "execution_count": 474,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cbwd data changed to number : {SE : 0, NW: 1, cv: 2, NE:3} \n",
            "cnn_x_train : 800, cnn_x_val : 100, cnn_x_test length: 100\n",
            "lstm_x_train : 800, lstm_x_val : 100, lstm_x_test length: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g68JCQXfatfb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9eac333c-709a-41f2-91a1-e79e74dd1db5"
      },
      "source": [
        "trainer.make_datagenerator(lstm_data_len = 15, cnn_data_len=15, batch_size = 1)"
      ],
      "execution_count": 475,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cnn_train_data_gen length : 785 // data_len: 15\n",
            "cnn_val_data_gen length : 85 // data_len: 15\n",
            "cnn_test_data_gen length : 85 // data_len: 15\n",
            "lstm_train_data_gen length : 785 // data_len: 15\n",
            "lstm_val_data_gen length : 85 // data_len: 15\n",
            "lstm_test_data_gen length : 85 // data_len: 15\n",
            "total data generator generated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrDBS24a6XpG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "c7d83e07-c9bc-495c-fe8e-4f0518c86998"
      },
      "source": [
        "model = trainer.generate_model()"
      ],
      "execution_count": 476,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_42\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_59 (InputLayer)           [(None, 1, 15, 7)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_29 (Conv2DTran (None, 2, 16, 32)    928         input_59[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling2D) (None, 1, 8, 32)     0           conv2d_transpose_29[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten_28 (Flatten)            (None, 256)          0           max_pooling2d_28[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_72 (Dropout)            (None, 256)          0           flatten_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_100 (Dense)               (None, 100)          25700       dropout_72[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_101 (Dense)               (None, 1)            101         dense_100[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_60 (InputLayer)           [(None, 1, 15)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_25 (Reshape)            (None, 1, 1)         0           dense_101[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 1, 16)        0           input_60[0][0]                   \n",
            "                                                                 reshape_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lstm_23 (LSTM)                  (None, 216)          201312      concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_73 (Dropout)            (None, 216)          0           lstm_23[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_102 (Dense)               (None, 128)          27776       dropout_73[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_74 (Dropout)            (None, 128)          0           dense_102[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_103 (Dense)               (None, 1)            129         dropout_74[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 255,946\n",
            "Trainable params: 255,946\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_ACBtptBrzA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        },
        "outputId": "5487a1e3-f583-45b8-ef04-f2f7cf4632ae"
      },
      "source": [
        "trainer.fit(epochs=1)"
      ],
      "execution_count": 477,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 1, 15, 7) for input Tensor(\"input_59:0\", shape=(None, 1, 15, 7), dtype=float32), but it was called on an input with incompatible shape (None, None, None).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-477-62d935ea4cba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-471-2a14bf8b41f0>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# 모델 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_train_data_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:386 call\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:180 assert_input_compatibility\n        str(x.shape.as_list()))\n\n    ValueError: Input 0 of layer conv2d_transpose_29 is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: [None, None, None]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2pO_Ba5U1C-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "45c51f19-20a9-4646-cd04-2d253dd80a58"
      },
      "source": [
        "trainer.cnn_train_data_gen[9999999]"
      ],
      "execution_count": 481,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[0.08      , 0.7037037 , 0.51851852, 0.        , 0.30384113,\n",
              "          0.        , 0.        ],\n",
              "         [0.2       , 0.7037037 , 0.55555556, 0.        , 0.33079937,\n",
              "          0.        , 0.        ],\n",
              "         [0.28      , 0.66666667, 0.55555556, 0.        , 0.34426175,\n",
              "          0.        , 0.        ],\n",
              "         [0.24      , 0.66666667, 0.55555556, 0.        , 0.35025619,\n",
              "          0.        , 0.        ],\n",
              "         [0.24      , 0.55555556, 0.59259259, 0.33333333, 0.00147349,\n",
              "          0.        , 0.        ],\n",
              "         [0.24      , 0.62962963, 0.55555556, 0.        , 0.01195539,\n",
              "          0.        , 0.        ],\n",
              "         [0.2       , 0.62962963, 0.55555556, 0.        , 0.02243729,\n",
              "          0.        , 0.        ],\n",
              "         [0.2       , 0.66666667, 0.55555556, 0.        , 0.03891363,\n",
              "          0.        , 0.        ],\n",
              "         [0.24      , 0.55555556, 0.55555556, 0.        , 0.04939553,\n",
              "          0.        , 0.        ],\n",
              "         [0.24      , 0.55555556, 0.51851852, 0.66666667, 0.00147349,\n",
              "          0.        , 0.        ],\n",
              "         [0.32      , 0.40740741, 0.51851852, 0.33333333, 0.00448746,\n",
              "          0.        , 0.        ],\n",
              "         [0.28      , 0.44444444, 0.48148148, 0.66666667, 0.00147349,\n",
              "          0.        , 0.        ],\n",
              "         [0.28      , 0.40740741, 0.44444444, 0.        , 0.00448746,\n",
              "          0.        , 0.        ],\n",
              "         [0.36      , 0.33333333, 0.44444444, 0.66666667, 0.00147349,\n",
              "          0.        , 0.        ],\n",
              "         [0.24      , 0.62962963, 0.44444444, 0.        , 0.01195539,\n",
              "          0.        , 0.        ]]]),\n",
              " array([[0.24      , 0.66666667, 0.48148148, 0.        , 0.03141221,\n",
              "         0.        , 0.        ]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 481
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMrLhT73ZSkA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}