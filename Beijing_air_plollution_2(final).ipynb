{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Beijing_air_plollution_2(final)",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1y-pdxy-P2Z8wSWKW-VVEv3k7QFrcbl_H",
      "authorship_tag": "ABX9TyO+TpZ2RC3gCyHd4FgI15Hp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YMGYM/TSE_Learning/blob/master/Beijing_air_plollution_2(final).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPythiWfQCnX",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "이 파일은 황철현, 신강욱의\n",
        "`미세먼지 예측 성능 개선을 위한 CNN-LSTM 결합 방법`\n",
        "논문의 구현 연습 파일입니다.\n",
        "\n",
        "데이터셋은 [Beijing PM2.5 데이터셋](https://www.kaggle.com/djhavera/beijing-pm25-data-data-set)\n",
        "을 사용했습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMnquIS4QfaO",
        "colab_type": "text"
      },
      "source": [
        "# Import All"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ9ZCMavQg_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as K\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miGdslSrQXBM",
        "colab_type": "text"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xY3TOYzQbgv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "312d731d-3c92-4559-da46-56372b21d84b"
      },
      "source": [
        "! unzip /content/drive/My\\ Drive/Datasets/beijing_air.zip -d data"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/Datasets/beijing_air.zip\n",
            "replace data/PRSA_data_2010.1.1-2014.12.31.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R5W7oRhQ6Ow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data():\n",
        "  all_data = pd.read_csv('/content/data/PRSA_data_2010.1.1-2014.12.31.csv') # 전체 데이터\n",
        "  dropped_data = all_data.drop(['No', 'year', 'month', 'day', 'hour'],axis=1) # 필요 없는 데이터는 버림\n",
        "  pm25 = dropped_data.pop('pm2.5') # 미세먼지 데이터 확인\n",
        "  pm25 = pm25.fillna(method='pad')\n",
        "  \n",
        "  return pm25, dropped_data"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5dnAMuOR1N0",
        "colab_type": "text"
      },
      "source": [
        "# Make Normalize Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhbeIxNDR1hX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PmScaler():\n",
        "  def __init__(self, pm25):\n",
        "    self.scaler = MinMaxScaler()\n",
        "    self.pm25 = pm25.fillna(1e-8, limit=1)\n",
        "    self.pm25 = self.pm25.fillna(method=\"pad\")\n",
        "    \n",
        "  def make_norlized_dataset(self, rate, x = None): \n",
        "    if x is None:\n",
        "      x = self.pm25\n",
        "    arrlen = int(len(x) * (rate))\n",
        "    if isinstance(x, type(np.array([]))) == False:\n",
        "      reshaped = x.to_numpy().reshape(-1,1)\n",
        "    else:\n",
        "      reshaped = x.reshape(-1,1)\n",
        "    scaled_data = self.scaler.fit_transform(reshaped)\n",
        "\n",
        "    train, val, test = scaled_data[:-1 * (arrlen * 2)], scaled_data[-1 * (arrlen * 2) : -1 * (arrlen)], scaled_data[-1 * (arrlen):]\n",
        "\n",
        "    return train, val, test\n",
        "  \n",
        "  def invert_scale(self, x):\n",
        "    inverse = self.scaler.inverse_transform(x)\n",
        "    return inverse"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri1ktmAkpauR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ProxyDataScaler():\n",
        "  def __init__(self, data):\n",
        "    self.table = data\n",
        "    self.scaler = MinMaxScaler()\n",
        "    \n",
        "  def change_cbwd_data(self):\n",
        "    mapping = {}\n",
        "    cols = self.table[\"cbwd\"].value_counts().index\n",
        "\n",
        "    for i, col in enumerate(cols):\n",
        "      mapping[col] = i # mapping = {\"SE\" : 0, \"NW\": 1, \"cv\": 2, \"NE\":3}\n",
        "    self.table = self.table.replace({'cbwd' : mapping})\n",
        "    print(\"cbwd data changed to number : {SE : 0, NW: 1, cv: 2, NE:3} \")\n",
        "\n",
        "  def make_normalize_data(self):\n",
        "    self.norm_data = self.scaler.fit_transform(self.table)\n",
        "    return self.norm_data\n",
        "\n",
        "  def slice_proxy_data(self, time):\n",
        "    col_cnt = len(self.table.columns)\n",
        "    if (self.norm_data is not None): # 정규화된 데이터가 있는지 확인\n",
        "      print(\"norm_data detected\")\n",
        "\n",
        "      if isinstance(self.norm_data, type(np.array([]))) == False: # 데이터를 numpy 형식으로 변환\n",
        "        data = self.norm_data.to_numpy().astype(\"float32\")\n",
        "      else:\n",
        "        data = self.norm_data.astype(\"float32\")\n",
        "\n",
        "    else:\n",
        "      print(\"norm_data not detected\")\n",
        "      data = self.table.to_numpy().astype(\"float32\")\n",
        "\n",
        "    self.sliced_data = np.zeros(shape=(1,time,col_cnt))\n",
        "\n",
        "    for i in range((len(data)-time) + 1):\n",
        "      if i == 0:\n",
        "        self.sliced_data = data[:i+time].reshape(1, time,-1)\n",
        "      else:\n",
        "        self.sliced_data = np.vstack((self.sliced_data, data[i:i+time].reshape(1,time,-1)))\n",
        "    return self.sliced_data\n",
        "\n",
        "  def split_data(self, data = None, rate = 0.1):\n",
        "    if data is None:\n",
        "      arrlen = int(len(self.sliced_data) * (rate))\n",
        "    else:\n",
        "      arrlen = int(len(data) * rate)\n",
        "\n",
        "    data = self.sliced_data\n",
        "    train, val, test = data[:-1 * (arrlen * 2)], data[-1 * (arrlen * 2) : -1 * (arrlen)], data[-1 * (arrlen):]\n",
        "\n",
        "    return train, val, test"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COffyY3ow6By",
        "colab_type": "text"
      },
      "source": [
        "# New LSTM Data generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weEk_Ih-w89V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMInputGenerator(K.utils.Sequence):\n",
        "  def __init__(self, lstm_x, lstm_y, data_len, cnn_output):\n",
        "    self.lstm_data_gen = K.preprocessing.sequence.TimeseriesGenerator(lstm_x, lstm_x, batch_size=1, length=data_len, shuffle=False)\n",
        "    self.cnn_output = cnn_output\n",
        "  def __getitem__(self, index):\n",
        "    lstm_x, lstm_y = self.lstm_data_gen[index]\n",
        "    stack_data = self.cnn_output[index].reshape(1,-1,1)\n",
        "    return_x = np.hstack((lstm_x, stack_data))\n",
        "    return return_x, lstm_y\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.cnn_output)"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iO5V6OhRZNJ",
        "colab_type": "text"
      },
      "source": [
        "# Entire Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arSPbMdqRepE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EntireModel():\n",
        "  def __init__(self, pm25, proxydata):\n",
        "    # -----------scaler 클래스 생성 -------------------\n",
        "    self.pm25 = pm25.fillna(1e-8, limit=1)\n",
        "    self.pm25 = self.pm25.fillna(method=\"pad\")\n",
        "    self.proxydata = proxydata\n",
        "    self.pmScaler = PmScaler(pm25)\n",
        "    self.proxyScaler = ProxyDataScaler(proxydata)\n",
        "    \n",
        "    # ---------- train 용 callbacks -----------\n",
        "    self.lstm_callbacks = [K.callbacks.TensorBoard(log_dir='lstm_logs')]\n",
        "    self.cnn_callbacks = [K.callbacks.TensorBoard(log_dir='cnn_logs')]\n",
        "\n",
        "  def make_proxy_data_generator(self, data_len = 2):\n",
        "    # ---------- proxy 데이터 전처리 -----------\n",
        "    self.proxyScaler.change_cbwd_data()\n",
        "    self.proxyScaler.make_normalize_data()\n",
        "    self.proxyScaler.make_normalize_data()\n",
        "    self.proxyScaler.slice_proxy_data(data_len)\n",
        "    cnn_x_train, cnn_x_val, cnn_x_test = self.proxyScaler.split_data(rate = 0.1)\n",
        "    self.grad_level = self._get_grad_pm25()\n",
        "    cnn_y_train, cnn_y_val, cnn_y_test = self._cnn_y_split(self.grad_level, data_len)\n",
        "    \n",
        "    # ---------- Data Generator 생성 ---------\n",
        "    self.cnn_train_data_gen = K.preprocessing.sequence.TimeseriesGenerator(cnn_x_train, cnn_y_train, length=1, batch_size = 128, shuffle=False)\n",
        "    self.cnn_val_data_gen = K.preprocessing.sequence.TimeseriesGenerator(cnn_x_val, cnn_y_val, length=1, batch_size = 128, shuffle=False)\n",
        "    self.cnn_test_data_gen = K.preprocessing.sequence.TimeseriesGenerator(cnn_x_test, cnn_y_test, length=1, batch_size = 1, shuffle=False)\n",
        "\n",
        "    # ----------- 모델 생성 --------------\n",
        "    print(\"Make CNN Model....\")\n",
        "    self.cnn_model = self._get_cnn_model(input_shape=(1, cnn_x_train.shape[1], cnn_x_train.shape[2]))\n",
        "\n",
        "  def make_lstm_data_generator(self, data_len = 15):\n",
        "    # ---------- pm25 데이터 전처리 -----------\n",
        "    pm25_x_train, pm25_x_val, pm25_x_test = self.pmScaler.make_norlized_dataset(rate = 0.1)\n",
        "\n",
        "    # ---------- pm25 Data Generator -------------\n",
        "    self.pm25_train_data_gen = K.preprocessing.sequence.TimeseriesGenerator(pm25_x_train, pm25_x_train, batch_size=1, length=data_len, shuffle=False)\n",
        "    self.pm25_val_data_gen = K.preprocessing.sequence.TimeseriesGenerator(pm25_x_val, pm25_x_val, batch_size = 1, length=data_len, shuffle=False)\n",
        "    self.pm25_test_data_gen = K.preprocessing.sequence.TimeseriesGenerator(pm25_x_test, pm25_x_test, batch_size = 1, length=data_len, shuffle=False)\n",
        "\n",
        "    # ---------- CNN result ------------\n",
        "    print(\"get CNN output..\")\n",
        "    self.cnn_train_output = self.cnn_model.predict(self.cnn_train_data_gen)\n",
        "    rated_cnn_train_output = self._make_lstm_input(self.cnn_train_output[data_len + 1:], self.pm25_train_data_gen)\n",
        "\n",
        "    self.cnn_val_output = self.cnn_model.predict(self.cnn_val_data_gen)\n",
        "    rated_cnn_val_output = self._make_lstm_input(self.cnn_val_output[data_len + 1:], self.pm25_val_data_gen)\n",
        "\n",
        "    self.cnn_test_output = self.cnn_model.predict(self.cnn_test_data_gen)\n",
        "    rated_cnn_test_output = self._make_lstm_input(self.cnn_test_output[data_len + 1:], self.pm25_test_data_gen)\n",
        "\n",
        "    # ---------- LSTM data gen ---------\n",
        "    self.lstm_train_data_gen = LSTMInputGenerator(pm25_x_train, pm25_x_train, data_len, rated_cnn_train_output)\n",
        "    self.lstm_val_data_gen = LSTMInputGenerator(pm25_x_val, pm25_x_val, data_len, rated_cnn_val_output)\n",
        "    self.lstm_test_data_gen = LSTMInputGenerator(pm25_x_test, pm25_x_test, data_len, rated_cnn_test_output)\n",
        "\n",
        "    # ---------- 모델 생성\n",
        "    print(\"make LSTM model...\")\n",
        "    self.lstm_model = self._get_lstm_model()\n",
        "\n",
        "  def cnn_model_fit(self, epochs=1):\n",
        "    self.cnn_model.fit(x=self.cnn_train_data_gen, epochs=epochs, validation_data=(self.cnn_val_data_gen), callbacks=self.cnn_callbacks)\n",
        "\n",
        "  def lstm_model_fit(self, epochs=1):\n",
        "    self.lstm_model.fit(x=self.lstm_train_data_gen, epochs=epochs, validation_data=self.lstm_val_data_gen, callbacks=self.lstm_callbacks)\n",
        "\n",
        "  def total_model_evaluate(self):\n",
        "    return self.lstm_model.evaluate(self.lstm_test_data_gen)\n",
        "\n",
        "  def _get_cnn_model(self, input_shape):\n",
        "    cnnModel = K.Sequential()\n",
        "    cnnModel.add(K.layers.Conv2DTranspose(32, (2,2), input_shape=input_shape, activation=\"relu\"))\n",
        "    cnnModel.add(K.layers.MaxPool2D(strides=2))\n",
        "    cnnModel.add(K.layers.Flatten())\n",
        "    cnnModel.add(K.layers.Dropout(0.1))\n",
        "    cnnModel.add(K.layers.Dense(100, activation=\"relu\"))\n",
        "    cnnModel.add(K.layers.ReLU())\n",
        "    cnnModel.add(K.layers.Dense(5, activation=\"softmax\"))\n",
        "    cnnModel.summary()\n",
        "    cnnModel.compile(optimizer=\"adam\", loss=\"MSE\")\n",
        "\n",
        "    return cnnModel\n",
        "\n",
        "  def _get_lstm_model(self):\n",
        "    lstm_model = K.Sequential()\n",
        "    lstm_model.add(K.layers.LSTM(216, input_shape=(16,1)))\n",
        "    lstm_model.add(K.layers.Dropout(0.3))\n",
        "    lstm_model.add(K.layers.Dense(128, activation=\"relu\"))\n",
        "    lstm_model.add(K.layers.Dropout(0.3))\n",
        "    lstm_model.add(K.layers.Dense(1, activation=\"sigmoid\"))\n",
        "    lstm_model.summary()\n",
        "    lstm_model.compile(optimizer=\"adam\", loss=\"MSE\")\n",
        "\n",
        "    return lstm_model\n",
        "\n",
        "  def _cnn_y_split(self, data, data_length, rate=0.1):\n",
        "    # cnn에 입력할 Y 데이터를 나눔\n",
        "    data = data[data_length-1:]\n",
        "    data = K.utils.to_categorical(data)\n",
        "    arrlen = int(len(data) * rate)\n",
        "\n",
        "    train, val, test =  data[:-1 * (arrlen * 2)], data[-1 * (arrlen * 2) : -1 * (arrlen)], data[-1 * (arrlen):]\n",
        "    return train, val, test\n",
        "\n",
        "  def _get_grad_pm25(self):\n",
        "    # pm25 의 변화율을 구하고 범주화함\n",
        "    grad_data = self.pm25.pct_change()\n",
        "    grad_data = grad_data.fillna(method=\"pad\")\n",
        "    bins = [-9.166667e-02, -1e-15,1e-15, 1.212121e-01]\n",
        "    grad_level = np.digitize(grad_data, bins=bins, right=False)\n",
        "    return grad_level\n",
        "\n",
        "  def _get_rate(self, data):\n",
        "    # 변화율 별로 pm25의 예측량을 구해봄(임시)\n",
        "    index = data.argmax()\n",
        "    if index == 3:\n",
        "      rate = 1\n",
        "    else:\n",
        "      rate = 1 + ((index-3) * 0.25) # 최대 50%의 변화율을 줘 봄\n",
        "\n",
        "    return rate\n",
        "  \n",
        "  def _compute_with_data(self, data, value):\n",
        "    # 예측량을 구함\n",
        "    rate = self._get_rate(data)\n",
        "    return rate * value\n",
        "\n",
        "  def _make_lstm_input(self, cnn_output, lstm_data_gen):\n",
        "    # 기존 lstm_input 에 위에서 구한 변화율을 곱한 뒤에 쌓음.\n",
        "    result = np.zeros(shape=(1,))\n",
        "    for i in range(len(cnn_output)):\n",
        "      lx, ly = lstm_data_gen[i]\n",
        "      if i == 0:\n",
        "        result = self._compute_with_data(cnn_output[i], ly.squeeze(axis=1))\n",
        "      else:\n",
        "        result = np.hstack((result, self._compute_with_data(cnn_output[i], ly.squeeze(axis=1))))\n",
        "    return result\n",
        "        "
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Da1JnS-Q3rl-",
        "colab_type": "text"
      },
      "source": [
        "# Model Init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUOca31BqV8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pm25, proxy = get_data()"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05e59Gkp4BwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = EntireModel(pm25, proxy)"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR6XIps6OLVr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "44269c9d-7691-413b-c014-85fca3dbd037"
      },
      "source": [
        "model.pm25"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        1.000000e-08\n",
              "1        1.000000e-08\n",
              "2        1.000000e-08\n",
              "3        1.000000e-08\n",
              "4        1.000000e-08\n",
              "             ...     \n",
              "43819    8.000000e+00\n",
              "43820    1.000000e+01\n",
              "43821    1.000000e+01\n",
              "43822    8.000000e+00\n",
              "43823    1.200000e+01\n",
              "Name: pm2.5, Length: 43824, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-eRVA1z4FPT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "8c507e5f-4f7e-4ce6-97f0-e11abde4aa3d"
      },
      "source": [
        "model.make_proxy_data_generator(data_len = 2)"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cbwd data changed to number : {SE : 0, NW: 1, cv: 2, NE:3} \n",
            "norm_data detected\n",
            "Make CNN Model....\n",
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_transpose_15 (Conv2DT (None, 2, 3, 32)          928       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 1, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_15 (Flatten)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 100)               3300      \n",
            "_________________________________________________________________\n",
            "re_lu_15 (ReLU)              (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 5)                 505       \n",
            "=================================================================\n",
            "Total params: 4,733\n",
            "Trainable params: 4,733\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEkiK5cS6OYh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ee49c97d-11a1-41f6-ee67-69afd8ac070f"
      },
      "source": [
        "model.cnn_model_fit(epochs=1)"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  2/274 [..............................] - ETA: 7s - loss: 0.1589WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0074s vs `on_train_batch_end` time: 0.0452s). Check your callbacks.\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.1560 - val_loss: 0.1530\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9OVQONU9Im3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "ca0d1f86-95eb-4eec-90cd-b7a2d3ed1154"
      },
      "source": [
        "model.make_lstm_data_generator(data_len = 15)"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "get CNN output..\n",
            "35042\n",
            "35045\n",
            "4365\n",
            "4367\n",
            "4365\n",
            "4367\n",
            "make LSTM model...\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_9 (LSTM)                (None, 216)               188352    \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 216)               0         \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 128)               27776     \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 216,257\n",
            "Trainable params: 216,257\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHMAShhZTc1O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7a0170d0-a1bb-4b71-cc06-ba8c486f55c3"
      },
      "source": [
        "print(model.cnn_train_output[3:].shape)\n",
        "print(model.pm25_train_data_gen.__len__())"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35055, 5)\n",
            "35045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwyX1BiYTvMm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "359a7532-0f91-4dc7-8c8a-8789390e53f9"
      },
      "source": [
        "model.lstm_train_data_gen.__len__()"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35042"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwRdaKZiMc4e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "fa7f7874-8d54-4989-d7d5-d129796d722b"
      },
      "source": [
        "model.lstm_model_fit(epochs=1)"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    2/35042 [..............................] - ETA: 36:02 - loss: 0.1835WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0225s vs `on_train_batch_end` time: 0.1007s). Check your callbacks.\n",
            "35042/35042 [==============================] - 551s 16ms/step - loss: 0.0018 - val_loss: 8.7366e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT-duD7y_N6s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "920f6260-6531-4618-ad4d-a2830a656115"
      },
      "source": [
        "result = model.total_model_evaluate()"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4365/4365 [==============================] - 10s 2ms/step - loss: 6.7893e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyGpq_6NW_N_",
        "colab_type": "text"
      },
      "source": [
        "# 수정 필요 사항\n",
        "- 데이터를 100% 활용 하는게 맞는가?\n",
        "- 학습 속도 증가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWmnZ3MuQDAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}